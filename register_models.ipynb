{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90da2e74-6d21-4ddd-a474-239fcdc30546",
   "metadata": {},
   "source": [
    "# Create Mapper Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b8e2a27-f09f-4774-a6d8-a21971f0faab",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import fileinput\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "from scipy.spatial.transform import Rotation\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import zscore\n",
    "import statistics\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c8bdd9-c580-4ec0-9550-aaefa94359a3",
   "metadata": {},
   "source": [
    "## Input Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0140977-f51e-47cb-8997-c2506122c8f1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#registered 5 central camera poses into right camera model now must align center and right model\n",
    "path_mapped = '/home/rapires/Documents/Exp_Thesis/OTANIEMI/otaniemi_25_04_2021/Models/mapper_Model/model1_cam_right_10fps/new_sparse'\n",
    "path_central = '/home/rapires/Documents/Exp_Thesis/OTANIEMI/otaniemi_25_04_2021/Models/model1_cam_center_10fps/sparse/0'\n",
    "\n",
    "cart_mapped = '/home/rapires/Documents/Exp_Thesis/python-scripts/data/cam_aligned_rightcenter10fps'\n",
    "cart_central = '/home/rapires/Documents/Exp_Thesis/python-scripts/data/camcentral_10fps'\n",
    "\n",
    "path_cart_mapped = Path(cart_mapped, 'img_cartesian.txt')\n",
    "path_cart_central = Path(cart_central, 'img_cartesian.txt')\n",
    "\n",
    "path_img_mapped = Path(path_mapped, 'images.txt')\n",
    "path_img_central = Path(path_central, 'images.txt')\n",
    "\n",
    "path_3d_mapped = Path(path_mapped, 'points3D.txt')\n",
    "path_3d_central = Path(path_central, 'points3D.txt')\n",
    "#colmap_data = extract_data_colmap(imagestxt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30be69de-07e3-4a78-b77b-72955e0b9adf",
   "metadata": {},
   "source": [
    "### extract data methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "083c3c57-2fa5-4e95-a668-866feedb479d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_data_3dpoints(filepath):\n",
    "    \"\"\"\n",
    "    Extracts data from a file generated by Colmap called points3D.txt,\n",
    "    changes collors of the points for visualization.\n",
    "    Returns:\n",
    "    [dict] pointid: its 3d coordinates list x,y,z\n",
    "    \"\"\"\n",
    "    line_count = 0\n",
    "    points_list = {}\n",
    "    \n",
    "    with open(filepath, \"r\") as f:\n",
    "        next(f)\n",
    "        next(f)\n",
    "        next(f)\n",
    "        all_lines = f.readlines()\n",
    "\n",
    "        for idx, line in enumerate(all_lines):\n",
    "            \n",
    "            point_id, x, y, z, r, g, b, _  = line.split()[:8]\n",
    "            track = line.split()[8:]\n",
    "\n",
    "            single_track = []\n",
    "            all_tracks = []\n",
    "            for idx2, line2 in enumerate(track):\n",
    "                single_track.append(line2)\n",
    "                if (idx2+1) % 2 == 0:\n",
    "                    all_tracks.append(single_track)\n",
    "                    single_track = []\n",
    "\n",
    "            #print(all_tracks)\n",
    "            if len(all_tracks) > 3:\n",
    "                points_list[point_id] = [x, y, z, r, g, b, all_tracks]\n",
    "            #break\n",
    "    od = collections.OrderedDict(sorted(points_list.items()))\n",
    "    points_list = dict(od)\n",
    "    return points_list\n",
    "\n",
    "\n",
    "def extract_data_colmap(filepath):\n",
    "    \"\"\"\n",
    "    This function extracts data from a file generated by the Colmap, called images.txt\n",
    "    track[] as imageid, point2did\n",
    "\n",
    "    Returns: \n",
    "    [Dictionary] image-name: image id, list of 2d keypoints and 3d points that are observed by the keypoints\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    with open(filepath, \"r\") as f:\n",
    "        next(f)  # skip the 3 header lines\n",
    "        next(f)\n",
    "        next(f)\n",
    "        next(f)\n",
    "        for idx, line in enumerate(f):\n",
    "            if idx % 2 == 0:\n",
    "                image_id, qw, qx, qy, qz, tx, ty, tz, _, image_name = line.split()\n",
    "                #image_name = images_path + image_name\n",
    "            else:\n",
    "                info = line.split()\n",
    "\n",
    "                keyframe = []\n",
    "                all_keyframes = []\n",
    "\n",
    "                for idx2, line2 in enumerate(info):\n",
    "\n",
    "                    keyframe.append(line2)\n",
    "                    if (idx2+1) % 3 == 0:\n",
    "                        '''if line2 != '-1':\n",
    "                            outer_list.append(inner_list)'''\n",
    "                        all_keyframes.append(keyframe)\n",
    "                        keyframe = []\n",
    "\n",
    "                data[image_id] = [image_name, all_keyframes, qw, qx, qy, qz, tx, ty, tz]\n",
    "            #break\n",
    "    od = collections.OrderedDict(sorted(data.items()))\n",
    "    data = dict(od)\n",
    "    return data\n",
    "\n",
    "def extract_img_cartesian(filepath):\n",
    "    \"\"\"Returns dict with image cartesian coordinates\"\"\"\n",
    "    #od = collections.OrderedDict(sorted(img_model.items())) Order dictionary of images\n",
    "    t = dict()\n",
    "    with open(filepath, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines:\n",
    "        key, values = tuple(line.split(':'))\n",
    "        #print(key)\n",
    "        key, img_id = tuple(key.split(', '))\n",
    "        values = list(str(re.sub(r'[\\[\\]\\n]','',values)).split(' '))\n",
    "        values = [float(i) for i in values if len(i) != 0]\n",
    "        values.append(img_id)\n",
    "        t[key] = values\n",
    "    od = collections.OrderedDict(sorted(t.items()))\n",
    "    t = dict(od)\n",
    "    return t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5c2843-8d51-4b5e-bc41-55cee1afdbe4",
   "metadata": {},
   "source": [
    "### Scale Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78c821f7-1010-475d-8e64-a73bd9a7cf18",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mean_increment(cart_mapped, cart_central, n = 5):\n",
    "    # estimates scale_bigmodel / scale_small model relation for the transformation based on camera poses\n",
    "    # n specifies camera index jump, n = 1 key 'center_1000' to 'center_1001', n = 2, key 'center_1000' to 'center_1002'\n",
    "    dif_mapped = get_diff(cart_mapped, n)\n",
    "    dif_central = get_diff(cart_central, n)\n",
    "    \n",
    "    dif_mapped = sum(dif_mapped)/len(dif_mapped)\n",
    "    dif_central = sum(dif_central)/len(dif_central)\n",
    "    \n",
    "    increment = dif_mapped / dif_central\n",
    "    return increment\n",
    "    \n",
    "def get_diff(cart_img, n = 5):\n",
    "    \"\"\"returns list of the scalar differences among consecutive images\"\"\"\n",
    "    img_dif = list()\n",
    "    item = iter(cart_img.items())\n",
    "    key, value = next(item)\n",
    "    \n",
    "    for i in range(n-1): #images keys '<name>_<index>.jpg'\n",
    "        name, index = tuple(key.rsplit('_',1))\n",
    "        index = int(str(index.split('.')[0]))\n",
    "        \n",
    "        dif_v = np.array(cart_img[f'{name}_{str(index+i+1)}.jpg'][:3]) - np.array(cart_img[f'{name}_{str(index+i)}.jpg'][:3])\n",
    "        img_dif.append(np.linalg.norm(dif_v))\n",
    "        \n",
    "        #print(f'center_{str(index+i+1)} minus center_{str(index+i)} equals {np.linalg.norm(dif_v)}')            \n",
    "    return img_dif    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5322f45-f900-493d-8c09-d31156e02e52",
   "metadata": {},
   "source": [
    "### Tranformation methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "585fb7cb-4c2e-4556-aa0b-2600cee4c3af",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rotation_matrix(unit_1, unit_2):\n",
    "    \"\"\"ROTATION MATRIX\"\"\"\n",
    "    v = np.cross(unit_1, unit_2)\n",
    "    s = np.linalg.norm(v)\n",
    "    c = np.dot(unit_1, unit_2)\n",
    "\n",
    "    I = np.identity(3)\n",
    "    m = f'0 {float(-v[2])} {float(v[1])}; {float(v[2])} 0 {float(-v[0])}; {float(-v[1])} {float(v[0])} 0'\n",
    "    V = np.matrix(m)\n",
    "\n",
    "    R = I + V + (V**2)*(1/(1+c))\n",
    "\n",
    "    return R\n",
    "\n",
    "def get_uvectors(cart_img, name, n=150):\n",
    "    \"\"\"get avg unit vector\"\"\"\n",
    "    uvectors = list()\n",
    "    item = iter(cart_img.items())\n",
    "    key, value = next(item)\n",
    "    ref = cart_img[f'{name}_1000.jpg'][:3]\n",
    "    \n",
    "    start, index = tuple(key.rsplit('_',1))\n",
    "    index = int(str(index.split('.')[0]))\n",
    "    \n",
    "    for i in range(1,n):\n",
    "        v = np.array(cart_img[f'{name}_{index+i}.jpg'][:3]) - np.array(ref)\n",
    "        uv = v/np.linalg.norm(v)\n",
    "        uvectors.append(uv)\n",
    "    \n",
    "    mat = np.matrix(uvectors)\n",
    "    meanv = mat.mean(0)\n",
    "    meanv = np.asarray(meanv[0])[0]\n",
    "    mean_uv = meanv / np.linalg.norm(meanv)\n",
    "    return mean_uv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98d8176a-a929-47a5-a5e5-1e1013aa6266",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def match_cartesian(cart_central, cart_mapped, n):\n",
    "    \"\"\"match central cameras in both models, perform necessary scaling and rotations\"\"\"\n",
    "    scale = mean_increment(cart_mapped, cart_central, n)\n",
    "    #mapped model is slightly (5%) bigger than the central only based on 5 images might not need scaling\n",
    "    #print(scale)\n",
    "    mapped_uv = get_uvectors(cart_mapped,'right', n=5)\n",
    "    central_uv = get_uvectors(cart_central,'center', n=5)\n",
    "    \n",
    "    R = rotation_matrix(central_uv, mapped_uv)\n",
    "    \n",
    "    #print(mapped_uv), print(central_uv)\n",
    "    return scale, R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac683900-c01c-476b-a649-336fb493dbdf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_pcd(cart_img, points3d):\n",
    "    #with open(filepath) as f:\n",
    "    points = []\n",
    "    colors = []\n",
    "    for key, value in cart_img.items():\n",
    "        if 'center' in key:\n",
    "            #color = '0.788,0.301,0.878' #purple\n",
    "            color = [0.788, 0.301, 0.878]\n",
    "            colors.append(color)\n",
    "        else:\n",
    "            #color = '0.023, 0.698, 0.078' #green\n",
    "            color = [0.023, 0.698, 0.078]\n",
    "            colors.append(color)\n",
    "        point = [value[0], value[1], value[2]]\n",
    "        points.append(point)\n",
    "        #line = f'{value[0]}, {value[1]}, {value[2]}, {color}\\n' \n",
    "    for key, value in points3d.items(): \n",
    "        #color = '0.458, 0.458, 0.458\\n' #grey\n",
    "        #line = f'{value[0]}, {value[1]}, {value[2]}, {color}\\n' \n",
    "        color = [0.458, 0.458, 0.458]\n",
    "        point = [value[0], value[1], value[2]]\n",
    "        points.append(point)\n",
    "        colors.append(color)\n",
    "\n",
    "    pcd = o3d.geometry.PointCloud() \n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "    return pcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ea873d8-3e20-413b-bbca-b8c6bddf0810",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_plane(pcd):\n",
    "    \"\"\"find 8 points in plane of the COLMAP model which delimit the model\"\"\"\n",
    "    plane_model, inliers = pcd.segment_plane(distance_threshold=0.3,\n",
    "                                             ransac_n=10,\n",
    "                                             num_iterations=10000)\n",
    "    [a, b, c, d] = plane_model\n",
    "    #print(f\"Plane equation: {a:.2f}x + {b:.2f}y + {c:.2f}z + {d:.2f} = 0\")\n",
    "    #print(f'Normal Vector to the plane: {a: .2f}i + {b: .2f}j + {c: .2f}k')\n",
    "    normal = np.array([a,b,c])\n",
    "    unormal = normal/np.linalg.norm(normal)\n",
    "    #####\n",
    "    return unormal, plane_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5ab0d30-b4f2-462a-ad17-043fdefe0f6b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_angle(normal1, normal2):\n",
    "    \"\"\"get angle between two normal vectors from models aligned in same direction\"\"\"\n",
    "    dot_product = np.dot(normal1, normal2)\n",
    "    angle = np.arccos(dot_product)\n",
    "    return angle\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4dbb82-d03a-4d74-ac83-df9888187862",
   "metadata": {},
   "source": [
    "## Main (Registration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03a3e8ed-9628-49cc-9a10-91a176604ead",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.48524634  1.16190899 -1.22113382]\n"
     ]
    }
   ],
   "source": [
    "#1st extract data, and find spatial relations\n",
    "\n",
    "points3d_mapped = extract_data_3dpoints(path_3d_mapped)\n",
    "points3d_central = extract_data_3dpoints(path_3d_central)\n",
    "\n",
    "images_mapped = extract_data_colmap(path_img_mapped)\n",
    "images_central = extract_data_colmap(path_img_central)\n",
    "\n",
    "cart_mapped = extract_img_cartesian(path_cart_mapped)\n",
    "cart_central = extract_img_cartesian(path_cart_central)\n",
    "\n",
    "pcd_center = get_pcd(cart_central, points3d_central)\n",
    "pcd_mapped = get_pcd(cart_mapped, points3d_mapped)\n",
    "\n",
    "scale = mean_increment(cart_mapped, cart_central, n=5)\n",
    "\n",
    "mapped_uv = get_uvectors(cart_mapped,'right', n=100)\n",
    "central_uv = get_uvectors(cart_central,'center', n=100) \n",
    "\n",
    "\n",
    "R = rotation_matrix(mapped_uv, np.array([0,1,0]))\n",
    "pcd_mapped.rotate(R)\n",
    "R = rotation_matrix(central_uv, np.array([0,1,0]))\n",
    "pcd_center.rotate(R)\n",
    "\n",
    "#2nd write to open3d point cloud\n",
    "\n",
    "cnormal, cplane = find_plane(pcd_center)\n",
    "mnormal, mplane = find_plane(pcd_mapped)\n",
    "\n",
    "angle = get_angle(cnormal, mnormal)\n",
    "R = o3d.geometry.get_rotation_matrix_from_xyz((0, angle, 0))\n",
    "pcd_center.rotate(R)\n",
    "\n",
    "a = np.asarray(pcd_center.points)\n",
    "b = np.asarray(pcd_mapped.points)\n",
    "translation = b[0] - a[0]\n",
    "\n",
    "#print(a)\n",
    "#print(b)\n",
    "print(translation)\n",
    "pcd_center.translate(translation)\n",
    "o3d.visualization.draw_geometries([pcd_mapped, pcd_center])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5d0c3c-9982-41f0-b8ee-6891fe41e7a8",
   "metadata": {},
   "source": [
    "### Registration Output Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9dab650b-10b0-4fd8-a898-453d4876a767",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "variable = tuple((pcd_mapped, pcd_center, points3d_mapped, points3d_central, images_mapped, images_central, cart_mapped, cart_central))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf363774-2852-4913-9969-4b842202e022",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path = '/home/rapires/Documents/Exp_Thesis/python-scripts/data/cam_aligned_rightcenter10fps/1_Registration'\n",
    "output_model = Path(output_path, 'entire_model.txt')\n",
    "output_images_central = Path(output_path, 'images_central.txt')\n",
    "output_images_mapped = Path(output_path, 'images_mapped.txt')\n",
    "output_points_central = Path(output_path, 'points3d_central.txt')\n",
    "output_points_mapped = Path(output_path, 'points3d_mapped.txt')\n",
    "outputc_cartesian = Path(output_path, 'imgc_cartesian.txt')\n",
    "outputm_cartesian = Path(output_path, 'imgm_cartesian.txt')\n",
    "create_files = f'touch {output_model} {output_images_central} {output_images_mapped} {output_points_central} {output_points_mapped} {output_cartesian}'\n",
    "os.system(create_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5927ddae-2f81-4680-b783-4b5818787eb9",
   "metadata": {},
   "source": [
    "### Write to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee02250c-50ba-4cab-993c-6ad6d912d395",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_model(variable, output_model, output_images_mapped, output_images_central, output_points_central, output_points_mapped):\n",
    "    \"\"\"\"\"\"\n",
    "    pcd_mapped, pcd_center, points3d_mapped, points3d_center, images_mapped, images_center, cart_mapped, cart_central = variable\n",
    "    pmapped = np.asarray(pcd_mapped.points)\n",
    "    pcenter = np.asarray(pcd_center.points)\n",
    "    cmapped = np.asarray(pcd_mapped.colors)\n",
    "    ccenter = np.asarray(pcd_center.colors)\n",
    "    \n",
    "    pimg_mapped, pp3d_mapped, pimg_center, pp3d_center = [], [], [], []\n",
    "    \n",
    "    with open(output_model, 'w') as f:\n",
    "        for i in range(len(pmapped)):\n",
    "            line = f'{str(pmapped[i][0])}, {str(pmapped[i][1])}, {str(pmapped[i][2])}, '+\\\n",
    "            f'{str(cmapped[i][0])}, {str(cmapped[i][1])}, {str(cmapped[i][2])}\\n'\n",
    "            f.write(line)\n",
    "            if '0.458' not in str(cmapped[i]): # if not a 3d point, it's an image\n",
    "                pimg_mapped.append(pmapped[i])\n",
    "            else:\n",
    "                pp3d_mapped.append(pmapped[i])\n",
    "        \n",
    "        for i in range(len(pcenter)):\n",
    "            line = f'{str(pcenter[i][0])}, {str(pcenter[i][1])}, {str(pcenter[i][2])}, '+\\\n",
    "            f'{str(ccenter[i][0])}, {str(ccenter[i][1])}, {str(ccenter[i][2])}\\n'\n",
    "            f.write(line)\n",
    "            if '0.458' not in str(ccenter[i]): # if not a 3d point, it's an image\n",
    "                pimg_center.append(pcenter[i])\n",
    "            else:\n",
    "                pp3d_center.append(pcenter[i])\n",
    "        \n",
    "    for idx, (key, value) in enumerate(cart_mapped.items()):\n",
    "        cart_mapped[key] = np.append(pimg_mapped[idx], value[3])\n",
    "    \n",
    "    for idx, (key, value) in enumerate(cart_central.items()):\n",
    "        cart_central[key] = np.append(pimg_center[idx], value[3])\n",
    "        \n",
    "    write_cartesian(output_cartesian, cart_central, cart_mapped)\n",
    "    write_images(output_images_mapped, cart_mapped, images_mapped)\n",
    "    write_images(output_images_central, cart_central, images_central)\n",
    "    write_points(output_points_mapped, pp3d_mapped, points3d_mapped)\n",
    "    write_points(output_points_central, pp3d_center, points3d_central)\n",
    "    \n",
    "def write_cartesian(output_cartesian, cart1, cart2):\n",
    "    \"\"\"write to cartesian file\"\"\"\n",
    "    with open(output_cartesian,'w') as f:\n",
    "        for key, value in cart1.items():\n",
    "            line = f'{key}, {value[3]}: {value[:3]}'\n",
    "            line = re.sub(r\"'\", '', line) + '\\n'\n",
    "            f.write(line)\n",
    "        for key, value in cart2.items():\n",
    "            line = f'{key}, {value[3]}: {value[:3]}'\n",
    "            line = re.sub(r\"'\", '', line) + '\\n'\n",
    "            f.write(line)\n",
    "\n",
    "def write_points(output_points, pp3d, points3d):\n",
    "    \"\"\" write in points3d file\"\"\"\n",
    "    with open(output_points, 'w') as f:\n",
    "        start_line = f'# 3D point list with one line of data per point:\\n'+\\\n",
    "    f'# POINT3D_ID, X, Y, Z, R, G, B, ERROR, TRACK[] as (IMAGE_ID, POINT2D_IDX)\\n'+\\\n",
    "    f'# Number of points: {len(pp3d)}, mean track length: Nan\\n'\n",
    "        f.write(start_line)\n",
    "        \n",
    "        for idx, (key, value) in enumerate(points3d.items()):\n",
    "            line = f'{key} {pp3d[idx]} {value[3:6]}, error, {value[6]}'\n",
    "            line = re.sub(r\"[\\[\\]\\'\\',]\", '', line) + '\\n'\n",
    "            f.write(line)\n",
    "    \n",
    "def write_images(output_images, cart, images):\n",
    "    \"\"\" write in image.txt file\"\"\"\n",
    "    with open(output_images,'w') as f:\n",
    "        start_line = f'# Image list with two lines of data per image:\\n'+\\\n",
    "        '#   IMAGE_ID, X, Y, Z, NAME\\n'+\\\n",
    "        '#   POINTS2D[] as (X, Y, POINT3D_ID)\\n'+\\\n",
    "        f'#   Number of images: {len(images)}\\n'\n",
    "        f.write(start_line)\n",
    "\n",
    "        for key, value in cart.items():\n",
    "            img_key = value[3]\n",
    "            line = f'{img_key} {value[:3]} {key}'\n",
    "            nextline = f'{images[img_key][1]}'\n",
    "            line = re.sub(r\"[\\[\\]\\'\\',]\", '', line) + '\\n'\n",
    "            nextline = re.sub(r\"[\\[\\]\\'\\',]\", '', nextline) + '\\n'\n",
    "            f.write(line)\n",
    "            f.write(nextline)\n",
    "    \n",
    "    \n",
    "write_model(variable, output_model, output_images_mapped, output_images_central, output_points_central, output_points_mapped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f88e2d1-6d53-456d-996b-9acf2c967c72",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f2d61f4-897c-4f75-baaa-78b673078b44",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = '/home/rapires/Documents/Exp_Thesis/OTANIEMI/otaniemi_model/back_iphone_seq'\n",
    "original_path_3d = path +\"/sparse/0/points3D.txt\" #from the colmap model\n",
    "img_cartesian = 'data/big_otaniemi_model/img_cartesian.txt'\n",
    "\n",
    "points3d_bm = extract_data_3dpoints(original_path_3d)\n",
    "images_bm = extract_img_cartesian(img_cartesian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3cd17053-de42-43c9-a4d5-71f8d10c1d41",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "points3d_c = extract_data_3dpoints(output_points_central)\n",
    "points3d_m = extract_data_3dpoints(output_points_mapped)\n",
    "\n",
    "images_c = extract_img_cartesian(output_cartesian)\n",
    "images_m = extract_img_cartesian(output_cartesian)\n",
    "\n",
    "rm_keyc = [key for key, value in images_c.items() if 'right' in key]\n",
    "for key in rm_keyc:\n",
    "    images_c.pop(key, None)        \n",
    "rm_keym = [key for key, value in images_m.items() if 'center' in key]\n",
    "for key in rm_keym:\n",
    "    images_m.pop(key, None)        \n",
    "#my_dict.pop('key', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e68016-311e-4727-a35c-71ce5b3fa087",
   "metadata": {},
   "source": [
    "### Transform Output Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b28e69bb-b16c-4942-8ce3-84b429577621",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'center_10001.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-25345f0ac52d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_increment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_bm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#the mean increment will have to be the same\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-15fb51f12f7e>\u001b[0m in \u001b[0;36mmean_increment\u001b[0;34m(cart_mapped, cart_central, n)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# estimates scale_bigmodel / scale_small model relation for the transformation based on camera poses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# n specifies camera index jump, n = 1 key 'center_1000' to 'center_1001', n = 2, key 'center_1000' to 'center_1002'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdif_mapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_diff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcart_mapped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdif_central\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_diff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcart_central\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-15fb51f12f7e>\u001b[0m in \u001b[0;36mget_diff\u001b[0;34m(cart_img, n)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mdif_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcart_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'center_{str(index+i+1)}.jpg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcart_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'center_{str(index+i)}.jpg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mimg_dif\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdif_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'center_10001.jpg'"
     ]
    }
   ],
   "source": [
    "scale = mean_increment(images_bm, images_c, 100) #the mean increment will have to be the same\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef30ef2b-0a86-4cbb-9657-9229fc968b53",
   "metadata": {},
   "source": [
    "### Output Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5af557-d0eb-44ca-a55a-28bc042cc5f0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = '/home/rapires/Documents/Exp_Thesis/python-scripts/data/cam_aligned_rightcenter10fps/2_Transformation'\n",
    "pathc = Path(path, 'central')\n",
    "pathm = Path(path, 'mapped')\n",
    "outc_timages, outc_tpoints, outc_tmodel = Path(pathc, 'images.txt'), Path(pathc, 'points3D.txt'), Path(pathc, 't_model.txt')\n",
    "outm_timages, outm_tpoints, outm_tmodel = Path(pathm, 'images.txt'), Path(pathm, 'points3D.txt'), Path(pathm, 't_model.txt')\n",
    "create_files = f'touch {outc_timages} {outc_tpoints} {outc_tmodel} {outm_timages} {outm_tpoints} {outm_tmodel}'\n",
    "os.system(create_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afe901c-0b07-485e-976a-ba4094339034",
   "metadata": {},
   "source": [
    "### Testing Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a9b4942a-3ef3-4364-b7b1-e3e07b20503b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-dfc9dbd036dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcart_central\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "item = iter(cart_central.items())\n",
    "key, value = next(item)\n",
    "print(key)\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee27d61b-afaf-4040-b999-afad5696e957",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.054981296810657825\n"
     ]
    }
   ],
   "source": [
    "print(angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9251669-1c49-4a66-9061-6f71d6017079",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "['-1.0295790855357168', '-0.06436695077816014', '1.0834355799518396', '26', '27', '22', [['55', '3038'], ['57', '2829'], ['56', '3051'], ['58', '2885'], ['59', '2842'], ['62', '2867'], ['64', '2829'], ['63', '2844'], ['65', '2809']]]\n"
     ]
    }
   ],
   "source": [
    "item = iter(points3d_mapped.items())\n",
    "key, value = next(item)\n",
    "print(key)\n",
    "print(value)\n",
    "#print(list(range(5)))\n",
    "#print(len(images_central.keys()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
